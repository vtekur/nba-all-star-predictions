{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All-Star</th>\n",
       "      <th>Position</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Conference</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>GP</th>\n",
       "      <th>W%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Bradley Beal 2018-19</td>\n",
       "      <td>25</td>\n",
       "      <td>East</td>\n",
       "      <td>24.7255</td>\n",
       "      <td>5.0588</td>\n",
       "      <td>5.0980</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>1.3725</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Stephen Curry 2018-19</td>\n",
       "      <td>30</td>\n",
       "      <td>West</td>\n",
       "      <td>29.5500</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>5.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>James Harden 2018-19</td>\n",
       "      <td>29</td>\n",
       "      <td>West</td>\n",
       "      <td>36.3404</td>\n",
       "      <td>6.6596</td>\n",
       "      <td>8.1277</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>2.0851</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Kyrie Irving 2018-19</td>\n",
       "      <td>26</td>\n",
       "      <td>East</td>\n",
       "      <td>23.6512</td>\n",
       "      <td>4.7907</td>\n",
       "      <td>6.9302</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>1.7209</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Damian Lillard 2018-19</td>\n",
       "      <td>28</td>\n",
       "      <td>West</td>\n",
       "      <td>26.4118</td>\n",
       "      <td>4.5686</td>\n",
       "      <td>6.2549</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>1.0784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   All-Star Position                  Player  Age Conference      PPG     RPG  \\\n",
       "0      True        G    Bradley Beal 2018-19   25       East  24.7255  5.0588   \n",
       "1      True        G   Stephen Curry 2018-19   30       West  29.5500  5.1000   \n",
       "2      True        G    James Harden 2018-19   29       West  36.3404  6.6596   \n",
       "3      True        G    Kyrie Irving 2018-19   26       East  23.6512  4.7907   \n",
       "4      True        G  Damian Lillard 2018-19   28       West  26.4118  4.5686   \n",
       "\n",
       "      APG     BPG     SPG    GP      W%  \n",
       "0  5.0980  0.7843  1.3725  51.0  0.4314  \n",
       "1  5.4000  0.3500  1.1750  40.0  0.7059  \n",
       "2  8.1277  0.7234  2.0851  47.0  0.5800  \n",
       "3  6.9302  0.4651  1.7209  43.0  0.6275  \n",
       "4  6.2549  0.4902  1.0784  51.0  0.6154  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('nba_player_data_through_jan.csv')\n",
    "dataset.set_index('Player')\n",
    "dataset = dataset.drop(columns = 'Unnamed: 0')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "x = dataset[['PPG', 'RPG', 'APG', 'BPG', 'SPG', 'GP', 'W%']]\n",
    "y = dataset['All-Star']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.8)\n",
    "x_train_std = std_scaler.fit_transform(x_train)\n",
    "x_test_std = std_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithm Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_classification_algorithms(algos, class_names, x_train, x_test, y_train, y_test): \n",
    "    for classifier in algos: \n",
    "        model = classifier.fit(x_train, y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        print(classifier)\n",
    "        print(classification_report(y_test, preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      0.99      0.99      3004\n",
      "    All-Star       0.86      0.82      0.84       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.93      0.91      0.92      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      1.00      0.99      3004\n",
      "    All-Star       0.93      0.75      0.83       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.96      0.87      0.91      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99      3004\n",
      "    All-Star       0.87      0.71      0.78       208\n",
      "\n",
      "    accuracy                           0.97      3212\n",
      "   macro avg       0.92      0.85      0.88      3212\n",
      "weighted avg       0.97      0.97      0.97      3212\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99      3004\n",
      "    All-Star       0.88      0.74      0.80       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.93      0.87      0.89      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      0.94      0.96      3004\n",
      "    All-Star       0.49      0.88      0.63       208\n",
      "\n",
      "    accuracy                           0.93      3212\n",
      "   macro avg       0.74      0.91      0.80      3212\n",
      "weighted avg       0.96      0.93      0.94      3212\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      0.99      0.99      3004\n",
      "    All-Star       0.85      0.79      0.82       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.92      0.89      0.90      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      1.00      0.99      3004\n",
      "    All-Star       0.93      0.77      0.84       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.96      0.88      0.92      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.97      0.99      0.98      3004\n",
      "    All-Star       0.85      0.55      0.67       208\n",
      "\n",
      "    accuracy                           0.96      3212\n",
      "   macro avg       0.91      0.77      0.82      3212\n",
      "weighted avg       0.96      0.96      0.96      3212\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99      3004\n",
      "    All-Star       0.88      0.74      0.80       208\n",
      "\n",
      "    accuracy                           0.98      3212\n",
      "   macro avg       0.93      0.87      0.89      3212\n",
      "weighted avg       0.98      0.98      0.98      3212\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      0.94      0.96      3004\n",
      "    All-Star       0.49      0.88      0.63       208\n",
      "\n",
      "    accuracy                           0.93      3212\n",
      "   macro avg       0.74      0.91      0.80      3212\n",
      "weighted avg       0.96      0.93      0.94      3212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "classifiers.append(LogisticRegression())\n",
    "classifiers.append(tree.DecisionTreeClassifier())\n",
    "classifiers.append(RandomForestClassifier())\n",
    "classifiers.append(svm.SVC())\n",
    "classifiers.append(xgboost.XGBClassifier())\n",
    "classifiers.append(GaussianNB())\n",
    "check_classification_algorithms(classifiers, ['Non-All-Star', 'All-Star'], x_train_std, x_test_std, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99      2993\n",
      "    All-Star       0.90      0.71      0.79       219\n",
      "\n",
      "    accuracy                           0.97      3212\n",
      "   macro avg       0.94      0.85      0.89      3212\n",
      "weighted avg       0.97      0.97      0.97      3212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NEIGHBORS = 15\n",
    "nca = neighbors.NeighborhoodComponentsAnalysis(random_state = 42)\n",
    "knn = neighbors.KNeighborsClassifier(NEIGHBORS)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(x_train_std, y_train)\n",
    "knn_preds = nca_pipe.predict(x_test_std)\n",
    "target_names = ['Non-All-Star', 'All-Star']\n",
    "print(classification_report(y_test, knn_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['Prediction Probability'] = probs\n",
    "x_test['Prediction'] = preds\n",
    "x_test['All-Star'] = dataset.iloc[list(x_test.index),[0]]\n",
    "x_test['Player'] = dataset.iloc[list(x_test.index),[2]]\n",
    "x_test.to_csv('log-reg-predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-data-env",
   "language": "python",
   "name": "nba-data-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
