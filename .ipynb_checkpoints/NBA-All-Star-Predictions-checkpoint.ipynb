{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All-Star</th>\n",
       "      <th>Position</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Conference</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>GP</th>\n",
       "      <th>W%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Bradley Beal 2018-19</td>\n",
       "      <td>25</td>\n",
       "      <td>East</td>\n",
       "      <td>24.7255</td>\n",
       "      <td>5.0588</td>\n",
       "      <td>5.0980</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>1.3725</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Stephen Curry 2018-19</td>\n",
       "      <td>30</td>\n",
       "      <td>West</td>\n",
       "      <td>29.5500</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>5.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>James Harden 2018-19</td>\n",
       "      <td>29</td>\n",
       "      <td>West</td>\n",
       "      <td>36.3404</td>\n",
       "      <td>6.6596</td>\n",
       "      <td>8.1277</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>2.0851</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Kyrie Irving 2018-19</td>\n",
       "      <td>26</td>\n",
       "      <td>East</td>\n",
       "      <td>23.6512</td>\n",
       "      <td>4.7907</td>\n",
       "      <td>6.9302</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>1.7209</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>Damian Lillard 2018-19</td>\n",
       "      <td>28</td>\n",
       "      <td>West</td>\n",
       "      <td>26.4118</td>\n",
       "      <td>4.5686</td>\n",
       "      <td>6.2549</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>1.0784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.6154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   All-Star Position                  Player  Age Conference      PPG     RPG  \\\n",
       "0      True        G    Bradley Beal 2018-19   25       East  24.7255  5.0588   \n",
       "1      True        G   Stephen Curry 2018-19   30       West  29.5500  5.1000   \n",
       "2      True        G    James Harden 2018-19   29       West  36.3404  6.6596   \n",
       "3      True        G    Kyrie Irving 2018-19   26       East  23.6512  4.7907   \n",
       "4      True        G  Damian Lillard 2018-19   28       West  26.4118  4.5686   \n",
       "\n",
       "      APG     BPG     SPG    GP      W%  \n",
       "0  5.0980  0.7843  1.3725  51.0  0.4314  \n",
       "1  5.4000  0.3500  1.1750  40.0  0.7059  \n",
       "2  8.1277  0.7234  2.0851  47.0  0.5800  \n",
       "3  6.9302  0.4651  1.7209  43.0  0.6275  \n",
       "4  6.2549  0.4902  1.0784  51.0  0.6154  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('nba_player_data_through_jan.csv')\n",
    "dataset.set_index('Player')\n",
    "dataset = dataset.drop(columns = 'Unnamed: 0')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "x = dataset[['PPG', 'RPG', 'APG', 'BPG', 'SPG', 'GP', 'W%']]\n",
    "y = dataset['All-Star']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.8)\n",
    "x_train_std = std_scaler.fit_transform(x_train)\n",
    "x_test_std = std_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithm Performance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_classification_algorithms(algos, class_names, x_train, x_test, y_train, y_test): \n",
    "    for classifier in algos: \n",
    "        model = classifier.fit(x_train, y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        print(classifier)\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        print(classification_report(y_test, preds, target_names=class_names))\n",
    "def check_classification_k_fold_cross_validation(kfoldtype, algos, class_names, x_data, y_data):\n",
    "    X, Y = np.array(x_data), np.array(y_data)\n",
    "    for classifier in algos:\n",
    "        cv_total_preds = []\n",
    "        cv_total_real = []\n",
    "        std_pipeline = classifier#make_pipeline(StandardScaler(), classifier)\n",
    "        for train_ind, test_ind in kfoldtype.split(X, y): \n",
    "            x_tr, x_te = X[train_ind], X[test_ind]\n",
    "            y_tr, y_te = Y[train_ind], y[test_ind]\n",
    "            std_pipeline.fit(x_tr, y_tr)\n",
    "            preds = std_pipeline.predict(x_te)\n",
    "            cv_total_real = np.append(cv_total_real,y_te)\n",
    "            cv_total_preds = np.append(cv_total_preds, preds)\n",
    "        print(classifier)\n",
    "        print(confusion_matrix(cv_total_real, cv_total_preds))\n",
    "        print(classification_report(cv_total_real, cv_total_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[[14944   136]\n",
      " [  283   694]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99     15080\n",
      "    All-Star       0.84      0.71      0.77       977\n",
      "\n",
      "    accuracy                           0.97     16057\n",
      "   macro avg       0.91      0.85      0.88     16057\n",
      "weighted avg       0.97      0.97      0.97     16057\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
      "                     weights='uniform')\n",
      "[[15009    71]\n",
      " [  315   662]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      1.00      0.99     15080\n",
      "    All-Star       0.90      0.68      0.77       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.94      0.84      0.88     16057\n",
      "weighted avg       0.97      0.98      0.97     16057\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "[[15023    57]\n",
      " [  221   756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      1.00      0.99     15080\n",
      "    All-Star       0.93      0.77      0.84       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.96      0.89      0.92     16057\n",
      "weighted avg       0.98      0.98      0.98     16057\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[15049    31]\n",
      " [  225   752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      1.00      0.99     15080\n",
      "    All-Star       0.96      0.77      0.85       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.97      0.88      0.92     16057\n",
      "weighted avg       0.98      0.98      0.98     16057\n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "[[14943   137]\n",
      " [  268   709]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99     15080\n",
      "    All-Star       0.84      0.73      0.78       977\n",
      "\n",
      "    accuracy                           0.97     16057\n",
      "   macro avg       0.91      0.86      0.88     16057\n",
      "weighted avg       0.97      0.97      0.97     16057\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[[14987    93]\n",
      " [  259   718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99     15080\n",
      "    All-Star       0.89      0.73      0.80       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.93      0.86      0.90     16057\n",
      "weighted avg       0.98      0.98      0.98     16057\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "[[14977   103]\n",
      " [  235   742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.98      0.99      0.99     15080\n",
      "    All-Star       0.88      0.76      0.81       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.93      0.88      0.90     16057\n",
      "weighted avg       0.98      0.98      0.98     16057\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[[14109   971]\n",
      " [   95   882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      0.94      0.96     15080\n",
      "    All-Star       0.48      0.90      0.62       977\n",
      "\n",
      "    accuracy                           0.93     16057\n",
      "   macro avg       0.73      0.92      0.79     16057\n",
      "weighted avg       0.96      0.93      0.94     16057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "classifiers.append(LogisticRegression())\n",
    "classifiers.append(KNeighborsClassifier(15))\n",
    "classifiers.append(tree.DecisionTreeClassifier())\n",
    "classifiers.append(RandomForestClassifier())\n",
    "classifiers.append(AdaBoostClassifier())\n",
    "classifiers.append(svm.SVC())\n",
    "classifiers.append(xgboost.XGBClassifier())\n",
    "classifiers.append(GaussianNB())\n",
    "kfold = StratifiedKFold(10, True, 42)\n",
    "check_classification_k_fold_cross_validation(kfold, classifiers, ['Non-All-Star', 'All-Star'], x ,y)\n",
    "#Random Forest Seems to have the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors w/ NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEIGHBORS = 15\n",
    "nca = NeighborhoodComponentsAnalysis(random_state = 42)\n",
    "knn = KNeighborsClassifier(NEIGHBORS)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(x_train_std, y_train)\n",
    "knn_preds = nca_pipe.predict(x_test_std)\n",
    "target_names = ['Non-All-Star', 'All-Star']\n",
    "print(classification_report(y_test, knn_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search CV For Random Forest\n",
    "Used as reference: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 1)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 29.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_job...\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 10],\n",
       "                                        'min_samples_split': [2, 5, 10, 20],\n",
       "                                        'n_estimators': [10, 231, 452, 673, 894,\n",
       "                                                         1115, 1336, 1557, 1778,\n",
       "                                                         2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_forest = RandomForestClassifier()\n",
    "tuned_r_forest = RandomizedSearchCV(estimator = r_forest, \n",
    "                               param_distributions = random_grid, scoring='f1', n_iter = 100, cv = 10, \n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "tuned_r_forest.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1336,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[15044    36]\n",
      " [  209   768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      1.00      0.99     15080\n",
      "    All-Star       0.96      0.79      0.86       977\n",
      "\n",
      "    accuracy                           0.98     16057\n",
      "   macro avg       0.97      0.89      0.93     16057\n",
      "weighted avg       0.98      0.98      0.98     16057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_r_forest.best_params_\n",
    "check_classification_k_fold_cross_validation(kfold, [tuned_r_forest.best_estimator_], ['Non-All-Star', 'All-Star'], x ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier(constant=0, random_state=None, strategy='constant')\n",
      "[[15080     0]\n",
      " [  977     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.94      1.00      0.97     15080\n",
      "    All-Star       0.00      0.00      0.00       977\n",
      "\n",
      "    accuracy                           0.94     16057\n",
      "   macro avg       0.47      0.50      0.48     16057\n",
      "weighted avg       0.88      0.94      0.91     16057\n",
      "\n",
      "DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "[[14168   912]\n",
      " [  922    55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.94      0.94      0.94     15080\n",
      "    All-Star       0.06      0.06      0.06       977\n",
      "\n",
      "    accuracy                           0.89     16057\n",
      "   macro avg       0.50      0.50      0.50     16057\n",
      "weighted avg       0.89      0.89      0.89     16057\n",
      "\n",
      "DummyClassifier(constant=None, random_state=None, strategy='prior')\n",
      "[[15080     0]\n",
      " [  977     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.94      1.00      0.97     15080\n",
      "    All-Star       0.00      0.00      0.00       977\n",
      "\n",
      "    accuracy                           0.94     16057\n",
      "   macro avg       0.47      0.50      0.48     16057\n",
      "weighted avg       0.88      0.94      0.91     16057\n",
      "\n",
      "DummyClassifier(constant=None, random_state=None, strategy='uniform')\n",
      "[[7550 7530]\n",
      " [ 495  482]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.94      0.50      0.65     15080\n",
      "    All-Star       0.06      0.49      0.11       977\n",
      "\n",
      "    accuracy                           0.50     16057\n",
      "   macro avg       0.50      0.50      0.38     16057\n",
      "weighted avg       0.89      0.50      0.62     16057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vtek/nba-data-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vtek/nba-data-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[15040    40]\n",
      " [  195   782]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-All-Star       0.99      1.00      0.99     15080\n",
      "    All-Star       0.95      0.80      0.87       977\n",
      "\n",
      "    accuracy                           0.99     16057\n",
      "   macro avg       0.97      0.90      0.93     16057\n",
      "weighted avg       0.99      0.99      0.98     16057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforestcomp = []\n",
    "#Using a old set of best parameters that appears to work well\n",
    "best_param_test = RandomForestClassifier(n_estimators = 100, min_samples_split=5, min_samples_leaf=1,\n",
    "                                        max_features='sqrt', max_depth=None, bootstrap=False)\n",
    "rforestcomp.append(DummyClassifier(strategy='constant', constant=0))\n",
    "rforestcomp.append(DummyClassifier('stratified'))\n",
    "rforestcomp.append(DummyClassifier('prior'))\n",
    "rforestcomp.append(DummyClassifier('uniform'))\n",
    "rforestcomp.append(best_param_test)                               \n",
    "check_classification_k_fold_cross_validation(kfold, rforestcomp, ['Non-All-Star', 'All-Star'], x ,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Using Tuned Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-data-env",
   "language": "python",
   "name": "nba-data-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
